{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "  \"cells\": [\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"0aStgWSO0E0E\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"# Classification\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"1eLEkw5O0ECa\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## Objectives\\n\",\n",
    "        \"\\n\",\n",
    "        \"*   Fit and evaluate a classification model to predict if a prospect will churn or not.\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"## Inputs\\n\",\n",
    "        \"\\n\",\n",
    "        \"* outputs/datasets/collection/TelcoCustomerChurn.csv\\n\",\n",
    "        \"* Instructions on which variables to use for data cleaning and feature engineering. They are found in each respective notebook.\\n\",\n",
    "        \"\\n\",\n",
    "        \"## Outputs\\n\",\n",
    "        \"\\n\",\n",
    "        \"* Train set (features and target)\\n\",\n",
    "        \"* Test set (features and target)\\n\",\n",
    "        \"* Data cleaning and Feature Engineering pipeline\\n\",\n",
    "        \"* Modeling pipeline\\n\",\n",
    "        \"* Feature importance plot\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"9uWZXH9LwoQg\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"---\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"# Change working directory\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"We need to change the working directory from its current folder to its parent folder\\n\",\n",
    "        \"* We access the current directory with os.getcwd()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"import os\\n\",\n",
    "        \"current_dir = os.getcwd()\\n\",\n",
    "        \"current_dir\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"We want to make the parent of the current directory the new current directory.\\n\",\n",
    "        \"* os.path.dirname() gets the parent directory\\n\",\n",
    "        \"* os.chir() defines the new current directory\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"os.chdir(os.path.dirname(current_dir))\\n\",\n",
    "        \"print(\\\"You set a new current directory\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"Confirm the new current directory\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"current_dir = os.getcwd()\\n\",\n",
    "        \"current_dir\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"OSpFreVRiuM3\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"---\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"-mavJ8DibrcQ\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"# Step 1: Load Data\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"Xk7DU_ekbtX8\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"import numpy as np\\n\",\n",
    "        \"import pandas as pd\\n\",\n",
    "        \"df = (pd.read_csv(\\\"outputs/datasets/collection/TelcoCustomerChurn.csv\\\")\\n\",\n",
    "        \"      .drop(labels=['tenure', 'customerID', 'TotalCharges'], axis=1)  \\n\",\n",
    "        \"                    # target variable for regressor, remove from classifier  \\n\",\n",
    "        \"                    # drop other variables we will not need for this project\\n\",\n",
    "        \"  )\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(df.shape)\\n\",\n",
    "        \"df.head(3)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"Ofil7xTpm6l9\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"---\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"krjAk78Tbyhv\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"# Step 2: ML Pipeline with all data\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"FfCsXhBYVBJw\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## ML pipeline for Data Cleaning and Feature Engineering\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"C6keis6ao8LA\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"from sklearn.pipeline import Pipeline\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Feature Engineering\\n\",\n",
    "        \"from feature_engine.selection import SmartCorrelatedSelection\\n\",\n",
    "        \"from feature_engine.encoding import OrdinalEncoder\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"def PipelineDataCleaningAndFeatureEngineering():\\n\",\n",
    "        \"    pipeline_base = Pipeline([\\n\",\n",
    "        \"        (\\\"OrdinalCategoricalEncoder\\\", OrdinalEncoder(encoding_method='arbitrary',\\n\",\n",
    "        \"                                                     variables=['gender', 'Partner', 'Dependents', 'PhoneService',\\n\",\n",
    "        \"                                                                'MultipleLines', 'InternetService', 'OnlineSecurity',\\n\",\n",
    "        \"                                                                'OnlineBackup', 'DeviceProtection', 'TechSupport',\\n\",\n",
    "        \"                                                                'StreamingTV', 'StreamingMovies', 'Contract',\\n\",\n",
    "        \"                                                                'PaperlessBilling', 'PaymentMethod'])),\\n\",\n",
    "        \"\\n\",\n",
    "        \"        (\\\"SmartCorrelatedSelection\\\", SmartCorrelatedSelection(variables=None,\\n\",\n",
    "        \"         method=\\\"spearman\\\", threshold=0.6, selection_method=\\\"variance\\\")),\\n\",\n",
    "        \"\\n\",\n",
    "        \"    ])\\n\",\n",
    "        \"\\n\",\n",
    "        \"    return pipeline_base\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"PipelineDataCleaningAndFeatureEngineering()\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"H_7BXNYMULrf\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## ML Pipeline for Modelling and Hyperparameter Optimisation\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"PYR4hz6-Ldvo\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Feat Scaling\\n\",\n",
    "        \"from sklearn.preprocessing import StandardScaler\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Feat Selection\\n\",\n",
    "        \"from sklearn.feature_selection import SelectFromModel\\n\",\n",
    "        \"\\n\",\n",
    "        \"# ML algorithms\\n\",\n",
    "        \"from sklearn.linear_model import LogisticRegression\\n\",\n",
    "        \"from sklearn.tree import DecisionTreeClassifier\\n\",\n",
    "        \"from sklearn.ensemble import RandomForestClassifier\\n\",\n",
    "        \"from sklearn.ensemble import GradientBoostingClassifier\\n\",\n",
    "        \"from sklearn.ensemble import ExtraTreesClassifier\\n\",\n",
    "        \"from sklearn.ensemble import AdaBoostClassifier\\n\",\n",
    "        \"from xgboost import XGBClassifier\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"def PipelineClf(model):\\n\",\n",
    "        \"    pipeline_base = Pipeline([\\n\",\n",
    "        \"        (\\\"scaler\\\", StandardScaler()),\\n\",\n",
    "        \"        (\\\"feat_selection\\\", SelectFromModel(model)),\\n\",\n",
    "        \"        (\\\"model\\\", model),\\n\",\n",
    "        \"    ])\\n\",\n",
    "        \"\\n\",\n",
    "        \"    return pipeline_base\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"KM_hrtfjLj85\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"Custom Class for Hyperparameter Optimisation\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"NpTcVDtQ5RMc\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"from sklearn.model_selection import GridSearchCV\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"class HyperparameterOptimizationSearch:\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def __init__(self, models, params):\\n\",\n",
    "        \"        self.models = models\\n\",\n",
    "        \"        self.params = params\\n\",\n",
    "        \"        self.keys = models.keys()\\n\",\n",
    "        \"        self.grid_searches = {}\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\\n\",\n",
    "        \"        for key in self.keys:\\n\",\n",
    "        \"            print(f\\\"\\\\nRunning GridSearchCV for {key} \\\\n\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"            model = PipelineClf(self.models[key])\\n\",\n",
    "        \"            params = self.params[key]\\n\",\n",
    "        \"            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\\n\",\n",
    "        \"                              verbose=verbose, scoring=scoring, )\\n\",\n",
    "        \"            gs.fit(X, y)\\n\",\n",
    "        \"            self.grid_searches[key] = gs\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def score_summary(self, sort_by='mean_score'):\\n\",\n",
    "        \"        def row(key, scores, params):\\n\",\n",
    "        \"            d = {\\n\",\n",
    "        \"                'estimator': key,\\n\",\n",
    "        \"                'min_score': min(scores),\\n\",\n",
    "        \"                'max_score': max(scores),\\n\",\n",
    "        \"                'mean_score': np.mean(scores),\\n\",\n",
    "        \"                'std_score': np.std(scores),\\n\",\n",
    "        \"            }\\n\",\n",
    "        \"            return pd.Series({**params, **d})\\n\",\n",
    "        \"\\n\",\n",
    "        \"        rows = []\\n\",\n",
    "        \"        for k in self.grid_searches:\\n\",\n",
    "        \"            params = self.grid_searches[k].cv_results_['params']\\n\",\n",
    "        \"            scores = []\\n\",\n",
    "        \"            for i in range(self.grid_searches[k].cv):\\n\",\n",
    "        \"                key = \\\"split{}_test_score\\\".format(i)\\n\",\n",
    "        \"                r = self.grid_searches[k].cv_results_[key]\\n\",\n",
    "        \"                scores.append(r.reshape(len(params), 1))\\n\",\n",
    "        \"\\n\",\n",
    "        \"            all_scores = np.hstack(scores)\\n\",\n",
    "        \"            for p, s in zip(params, all_scores):\\n\",\n",
    "        \"                rows.append((row(k, s, p)))\\n\",\n",
    "        \"\\n\",\n",
    "        \"        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\\n\",\n",
    "        \"        columns = ['estimator', 'min_score',\\n\",\n",
    "        \"                   'mean_score', 'max_score', 'std_score']\\n\",\n",
    "        \"        columns = columns + [c for c in df.columns if c not in columns]\\n\",\n",
    "        \"        return df[columns], self.grid_searches\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"eUcOp83jy0QG\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## Split Train and Test Set\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"0vqzNI2zF1sZ\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"from sklearn.model_selection import train_test_split\\n\",\n",
    "        \"X_train, X_test, y_train, y_test = train_test_split(\\n\",\n",
    "        \"    df.drop(['Churn'], axis=1),\\n\",\n",
    "        \"    df['Churn'],\\n\",\n",
    "        \"    test_size=0.2,\\n\",\n",
    "        \"    random_state=0,\\n\",\n",
    "        \")\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"4zBysp0tyqR2\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## Handle Target Imbalance\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"MsQRvnn1GI_d\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"pipeline_data_cleaning_feat_eng = PipelineDataCleaningAndFeatureEngineering()\\n\",\n",
    "        \"X_train = pipeline_data_cleaning_feat_eng.fit_transform(X_train)\\n\",\n",
    "        \"X_test = pipeline_data_cleaning_feat_eng.transform(X_test)\\n\",\n",
    "        \"print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"wuq3902arZAz\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"Check Train Set Target distribution\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"I28ACrp-rPgF\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"import matplotlib.pyplot as plt\\n\",\n",
    "        \"import seaborn as sns\\n\",\n",
    "        \"sns.set_style(\\\"whitegrid\\\")\\n\",\n",
    "        \"y_train.value_counts().plot(kind='bar', title='Train Set Target Distribution')\\n\",\n",
    "        \"plt.show()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"-OgoR6lTrKqY\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"Use SMOTE (Synthetic Minority Oversampling TEchnique) to balance Train Set target\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"tP1JIwXNEsXO\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"from imblearn.over_sampling import SMOTE\\n\",\n",
    "        \"oversample = SMOTE(sampling_strategy='minority', random_state=0)\\n\",\n",
    "        \"X_train, y_train = oversample.fit_resample(X_train, y_train)\\n\",\n",
    "        \"print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"vTJO6V5zrdnw\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"Check Train Set Target distribution after resampling\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"iQdvEvNRG80Y\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"import matplotlib.pyplot as plt\\n\",\n",
    "        \"y_train.value_counts().plot(kind='bar', title='Train Set Target Distribution')\\n\",\n",
    "        \"plt.show()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"j2xTTXMayvo6\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## Grid Search CV - Sklearn\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"fizLJ_YQ6elb\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"### Use standard hyperparameters to find most suitable algorithm \"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"kMgswohfKBda\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"models_quick_search = {\\n\",\n",
    "        \"    \\\"LogisticRegression\\\": LogisticRegression(random_state=0),\\n\",\n",
    "        \"    \\\"XGBClassifier\\\": XGBClassifier(random_state=0),\\n\",\n",
    "        \"    \\\"DecisionTreeClassifier\\\": DecisionTreeClassifier(random_state=0),\\n\",\n",
    "        \"    \\\"RandomForestClassifier\\\": RandomForestClassifier(random_state=0),\\n\",\n",
    "        \"    \\\"GradientBoostingClassifier\\\": GradientBoostingClassifier(random_state=0),\\n\",\n",
    "        \"    \\\"ExtraTreesClassifier\\\": ExtraTreesClassifier(random_state=0),\\n\",\n",
    "        \"    \\\"AdaBoostClassifier\\\": AdaBoostClassifier(random_state=0),\\n\",\n",
    "        \"}\\n\",\n",
    "        \"\\n\",\n",
    "        \"params_quick_search = {\\n\",\n",
    "        \"    \\\"LogisticRegression\\\": {},\\n\",\n",
    "        \"    \\\"XGBClassifier\\\": {},\\n\",\n",
    "        \"    \\\"DecisionTreeClassifier\\\": {},\\n\",\n",
    "        \"    \\\"RandomForestClassifier\\\": {},\\n\",\n",
    "        \"    \\\"GradientBoostingClassifier\\\": {},\\n\",\n",
    "        \"    \\\"ExtraTreesClassifier\\\": {},\\n\",\n",
    "        \"    \\\"AdaBoostClassifier\\\": {},\\n\",\n",
    "        \"}\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"GXu0Ryeown7N\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"Quick GridSearch CV - Binary Classifier\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"O7eLJcKEKBlQ\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"from sklearn.metrics import make_scorer, recall_score\\n\",\n",
    "        \"search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\\n\",\n",
    "        \"search.fit(X_train, y_train,\\n\",\n",
    "        \"           scoring =  make_scorer(recall_score, pos_label=1),\\n\",\n",
    "        \"           n_jobs=-1, cv=5)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"g0bkL-IxwnJx\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"Check results\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"YpFOc7OAKMuz\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\\n\",\n",
    "        \"grid_search_summary \"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"ewezVDt46jTJ\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"### Do an extensive search on the most suitable algorithm to find the best hyperparameter configuration.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"Z1WozH5frBQ9\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"Define model and parameters, for Extensive Search\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"sDT_WMUErBRB\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"models_search = {\\n\",\n",
    "        \"    \\\"XGBClassifier\\\":XGBClassifier(random_state=0),\\n\",\n",
    "        \"}\\n\",\n",
    "        \"\\n\",\n",
    "        \"# documentation to help on hyperparameter list: \\n\",\n",
    "        \"# https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn\\n\",\n",
    "        \"\\n\",\n",
    "        \"# We will not conduct an extensive search, since the focus\\n\",\n",
    "        \"# is on how to combine all knowledge in an applied project.\\n\",\n",
    "        \"# In a workplace project, you may spend more time in this step\\n\",\n",
    "        \"params_search = {\\n\",\n",
    "        \"    \\\"XGBClassifier\\\":{\\n\",\n",
    "        \"        'model__learning_rate': [1e-1,1e-2,1e-3], \\n\",\n",
    "        \"        'model__max_depth': [3,10,None],\\n\",\n",
    "        \"    }\\n\",\n",
    "        \"}\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"BP2Ua0FGrBRC\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"Extensive GridSearch CV - Binary Classifier\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"WK1s893orBRD\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"from sklearn.metrics import recall_score, make_scorer\\n\",\n",
    "        \"search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\\n\",\n",
    "        \"search.fit(X_train, y_train,\\n\",\n",
    "        \"           scoring =  make_scorer(recall_score, pos_label=1),\\n\",\n",
    "        \"           n_jobs=-1, cv=5)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"l8oVKtHyr-X8\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"Check results\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"8AFyZ6-pr9tN\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\\n\",\n",
    "        \"grid_search_summary \"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"Get best model name programmatically\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"best_model = grid_search_summary.iloc[0,0]\\n\",\n",
    "        \"best_model\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"htAXEVFpwiBV\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"Parameters for best model\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"oDIt27RdKOG8\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"best_parameters = grid_search_pipelines[best_model].best_params_\\n\",\n",
    "        \"best_parameters\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"eAnJQlDlw1FE\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"Define the best clf pipeline\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"zLotNfy4MKDE\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"pipeline_clf = grid_search_pipelines[best_model].best_estimator_\\n\",\n",
    "        \"pipeline_clf\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"UgdxKijH6qJS\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## Assess feature importance\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"X_train.head(3)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"n30pl2dowzW3\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"* With the current model, we can assess with `.features_importances_`\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"4XGczhv2uo2C\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# create DataFrame to display feature importance\\n\",\n",
    "        \"df_feature_importance = (pd.DataFrame(data={\\n\",\n",
    "        \"    'Feature': X_train.columns[pipeline_clf['feat_selection'].get_support()],\\n\",\n",
    "        \"    'Importance': pipeline_clf['model'].feature_importances_})\\n\",\n",
    "        \"    .sort_values(by='Importance', ascending=False)\\n\",\n",
    "        \")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# re-assign best_features order\\n\",\n",
    "        \"best_features = df_feature_importance['Feature'].to_list()\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Most important features statement and plot\\n\",\n",
    "        \"print(f\\\"* These are the {len(best_features)} most important features in descending order. \\\"\\n\",\n",
    "        \"      f\\\"The model was trained on them: \\\\n{df_feature_importance['Feature'].to_list()}\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\\n\",\n",
    "        \"plt.show()\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"hXtmFP_Ulpnd\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## Evaluate Pipeline on Train and Test Sets\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"myG6tDSGan4r\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"from sklearn.metrics import classification_report, confusion_matrix\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"def confusion_matrix_and_report(X, y, pipeline, label_map):\\n\",\n",
    "        \"\\n\",\n",
    "        \"    prediction = pipeline.predict(X)\\n\",\n",
    "        \"\\n\",\n",
    "        \"    print('---  Confusion Matrix  ---')\\n\",\n",
    "        \"    print(pd.DataFrame(confusion_matrix(y_true=prediction, y_pred=y),\\n\",\n",
    "        \"          columns=[[\\\"Actual \\\" + sub for sub in label_map]],\\n\",\n",
    "        \"          index=[[\\\"Prediction \\\" + sub for sub in label_map]]\\n\",\n",
    "        \"          ))\\n\",\n",
    "        \"    print(\\\"\\\\n\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"    print('---  Classification Report  ---')\\n\",\n",
    "        \"    print(classification_report(y, prediction, target_names=label_map), \\\"\\\\n\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"def clf_performance(X_train, y_train, X_test, y_test, pipeline, label_map):\\n\",\n",
    "        \"    print(\\\"#### Train Set #### \\\\n\\\")\\n\",\n",
    "        \"    confusion_matrix_and_report(X_train, y_train, pipeline, label_map)\\n\",\n",
    "        \"\\n\",\n",
    "        \"    print(\\\"#### Test Set ####\\\\n\\\")\\n\",\n",
    "        \"    confusion_matrix_and_report(X_test, y_test, pipeline, label_map)\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"qpUfEAGlW5aK\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"Evaluation: We cross check with metrics defined at ML business case\\n\",\n",
    "        \"* 80% Recall for Churn, on train and test set\\n\",\n",
    "        \"* 80% Precision for no Churn on train and test set. \"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"umWjIvGMNLig\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"clf_performance(X_train=X_train, y_train=y_train,\\n\",\n",
    "        \"                X_test=X_test, y_test=y_test,\\n\",\n",
    "        \"                pipeline=pipeline_clf,\\n\",\n",
    "        \"                label_map= ['No Churn', 'Churn'] \\n\",\n",
    "        \"                )\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"7WgttWjtHHOQ\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"# Step 3: Refit pipeline with best features\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"kCyOyebVHVmA\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## Refit ML Pipeline and Resampling\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"R4PpI2sKC5IL\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"In theory, a pipeline fitted **using only the most important features** should give the same result as the one fitted with **all variables and feature selection**\\n\",\n",
    "        \"\\n\",\n",
    "        \"* However, in this project we have a step for feature augmentation, which is to balance the target Train Set using SMOTE().\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"Km_-hW0f68DP\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## Rewrite ML pipeline for Data Cleaning and Feature Engineering\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"best_features\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"EBeckIjkCa4k\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"New Pipeline for DataCleaning And FeatureEngineering\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"bc8ptvFiHJmb\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"def PipelineDataCleaningAndFeatureEngineering():\\n\",\n",
    "        \"    pipeline_base = Pipeline([\\n\",\n",
    "        \"\\n\",\n",
    "        \"        (\\\"OrdinalCategoricalEncoder\\\", OrdinalEncoder(encoding_method='arbitrary',\\n\",\n",
    "        \"                                                     variables=['InternetService', 'Contract'])),\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # we don't need SmartCorrelatedSelection\\n\",\n",
    "        \"    ])\\n\",\n",
    "        \"\\n\",\n",
    "        \"    return pipeline_base\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"uGNs9PU16_Ls\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## Rewrite ML Pipeline for Modelling\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"gpjmxzTbCXlg\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"Function for Pipeline optmisation\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"8E76QmoMEWA0\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Pipeline Optmization: Model\\n\",\n",
    "        \"def PipelineClf(model):\\n\",\n",
    "        \"    pipeline_base = Pipeline([\\n\",\n",
    "        \"        (\\\"scaler\\\", StandardScaler()),\\n\",\n",
    "        \"        # no feature selection needed anymore!!! We know which features to use already!\\n\",\n",
    "        \"        (\\\"model\\\", model),\\n\",\n",
    "        \"    ])\\n\",\n",
    "        \"\\n\",\n",
    "        \"    return pipeline_base\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"75hfh3o5GhoU\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## Split Train Test Set, considering only with best features\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"x6dX0VeKGhod\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"from sklearn.model_selection import train_test_split\\n\",\n",
    "        \"X_train, X_test, y_train, y_test = train_test_split(\\n\",\n",
    "        \"    df.drop(['Churn'], axis=1),\\n\",\n",
    "        \"    df['Churn'],\\n\",\n",
    "        \"    test_size=0.2,\\n\",\n",
    "        \"    random_state=0,\\n\",\n",
    "        \")\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"c19a3t6jI6H6\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"We filter only the most important variables\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"p5Acb9T_GXjU\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"X_train = X_train.filter(best_features)\\n\",\n",
    "        \"X_test = X_test.filter(best_features)\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\\n\",\n",
    "        \"X_train.head(3)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"sjOcRGheGhof\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## Handle Target Imbalance\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"KbQda_pcGhof\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"pipeline_data_cleaning_feat_eng = PipelineDataCleaningAndFeatureEngineering()\\n\",\n",
    "        \"X_train = pipeline_data_cleaning_feat_eng.fit_transform(X_train)\\n\",\n",
    "        \"X_test = pipeline_data_cleaning_feat_eng.transform(X_test)\\n\",\n",
    "        \"print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"EQxIFw3KGhog\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"Check Train Set Target distribution\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"7ZQyth-2Ghog\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"import matplotlib.pyplot as plt\\n\",\n",
    "        \"y_train.value_counts().plot(kind='bar', title='Train Set Target Distribution')\\n\",\n",
    "        \"plt.show()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"N9FbCbIrGhoh\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"Use SMOTE to balance Train Set target\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"OtbWft5VGhoh\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"from imblearn.over_sampling import SMOTE\\n\",\n",
    "        \"oversample = SMOTE(sampling_strategy='minority', random_state=0)\\n\",\n",
    "        \"X_train, y_train = oversample.fit_resample(X_train, y_train)\\n\",\n",
    "        \"print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"YozwzI9eGhoh\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"Check Train Set Target distribution after SMOTE\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"TyL99cYMGhoi\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"y_train.value_counts().plot(kind='bar',title='Train Set Target Distribution')\\n\",\n",
    "        \"plt.show()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"b_WjvD_QIJ_L\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## Grid Search CV: Sklearn\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"ESkqrySI7N6u\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"Using the most suitable model from the last section and its best hyperparameter configuration.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"F6fFaXDOIJ_M\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"We are using the same model from  the last GridCV search\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"H7F0z__h1qSA\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"models_search   # XGBClassifier\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"qRteBPgd3ldU\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"And the best parameters from the last GridCV search \"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"IbGNBeZk3V8r\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"best_parameters\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"YlLJP5Ds3rYp\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"You will need to type in manually since the hyperparameter values have to be a list. The previous dictionary is not in this format.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"9bC8RmE-2Mi2\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"params_search = {'XGBClassifier':  {\\n\",\n",
    "        \"    'model__learning_rate': [0.01],   # the value should be in []\\n\",\n",
    "        \"    'model__max_depth': [3]},  # the value should be in []\\n\",\n",
    "        \"}\\n\",\n",
    "        \"params_search\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"GrRJNywsIJ_M\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"GridSearch CV\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"yv5nO6cJP9fX\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"from sklearn.metrics import recall_score, make_scorer\\n\",\n",
    "        \"quick_search = HyperparameterOptimizationSearch(\\n\",\n",
    "        \"    models=models_search, params=params_search)\\n\",\n",
    "        \"quick_search.fit(X_train, y_train,\\n\",\n",
    "        \"                 scoring=make_scorer(recall_score, pos_label=1),\\n\",\n",
    "        \"                 n_jobs=-1, cv=5)\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"Yr_Yu9ykIJ_N\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"Check results\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"fqIk1g95IJ_N\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"grid_search_summary, grid_search_pipelines = quick_search.score_summary(sort_by='mean_score')\\n\",\n",
    "        \"grid_search_summary \"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"tZcP3yXpIJ_O\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"Define the best clf pipeline\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"P7Qe2jFEIJ_O\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"best_model = grid_search_summary.iloc[0, 0]\\n\",\n",
    "        \"pipeline_clf = grid_search_pipelines[best_model].best_estimator_\\n\",\n",
    "        \"pipeline_clf\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"qXEXWvsb7Su0\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## Assess feature importance\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"T8UGZ5bnIJ_P\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"best_features = X_train.columns\\n\",\n",
    "        \"\\n\",\n",
    "        \"# create DataFrame to display feature importance\\n\",\n",
    "        \"df_feature_importance = (pd.DataFrame(data={\\n\",\n",
    "        \"    'Feature': best_features,\\n\",\n",
    "        \"    'Importance': pipeline_clf['model'].feature_importances_})\\n\",\n",
    "        \"    .sort_values(by='Importance', ascending=False)\\n\",\n",
    "        \")\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Most important features statement and plot\\n\",\n",
    "        \"print(f\\\"* These are the {len(best_features)} most important features in descending order. \\\"\\n\",\n",
    "        \"      f\\\"The model was trained on them: \\\\n{df_feature_importance['Feature'].to_list()}\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\\n\",\n",
    "        \"plt.show()\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"nQF20xan7VuK\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## Evaluate Pipeline on Train and Test Sets\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"Evaluation: We cross-check with metrics defined in the ML business case.\\n\",\n",
    "        \"* 80% Recall for Churn, on train and test set.\\n\",\n",
    "        \"* 80% Precision for no Churn on train and test set. \"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"1cpCj2lLHxB-\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"clf_performance(X_train=X_train, y_train=y_train,\\n\",\n",
    "        \"                X_test=X_test, y_test=y_test,\\n\",\n",
    "        \"                pipeline=pipeline_clf,\\n\",\n",
    "        \"                label_map= ['No Churn', 'Churn'] \\n\",\n",
    "        \"                )\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"oBVunRgBqIXQ\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"# Step 4: Push files to Repo\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"yxnlKI5SJcoO\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"We will generate the following files\\n\",\n",
    "        \"* Train set\\n\",\n",
    "        \"* Test set\\n\",\n",
    "        \"* Data cleaning and Feature Engineering pipeline\\n\",\n",
    "        \"* Modeling pipeline\\n\",\n",
    "        \"* features importance plot\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"16bIOgs3J7OD\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"import joblib\\n\",\n",
    "        \"import os\\n\",\n",
    "        \"\\n\",\n",
    "        \"version = 'v1'\\n\",\n",
    "        \"file_path = f'outputs/ml_pipeline/predict_churn/{version}'\\n\",\n",
    "        \"\\n\",\n",
    "        \"try:\\n\",\n",
    "        \"    os.makedirs(name=file_path)\\n\",\n",
    "        \"except Exception as e:\\n\",\n",
    "        \"    print(e)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"3e-gC6sa7hpj\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## Train Set\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"hHZUZKJ5JiKn\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"* note that the variables **are transformed already** in X_train and the shape is 8266 - after SMOTE was applied.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"Sc4fzrdTJno1\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"print(X_train.shape)\\n\",\n",
    "        \"X_train.head()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"Qzq7DgVTJnv3\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"X_train.to_csv(f\\\"{file_path}/X_train.csv\\\", index=False)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"DzPsdNGX9gtf\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"y_train\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"FMoT1cJ39g26\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"y_train.to_csv(f\\\"{file_path}/y_train.csv\\\", index=False)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"OYatlgsj7pbB\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## Test Set\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"tEKp3-dJJn3p\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"* note that the variables are transformed already in X_test\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"9UMg2vPtJqxM\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"print(X_test.shape)\\n\",\n",
    "        \"X_test.head()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"uz2OqPW6Jqzv\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"X_test.to_csv(f\\\"{file_path}/X_test.csv\\\", index=False)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"4pPTVz219xj3\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"y_test\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"ap7fYYAm9xsj\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"y_test.to_csv(f\\\"{file_path}/y_test.csv\\\", index=False)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"_ufHAplN7tdo\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## ML Pipelines: Data Cleaning and Feat Eng pipeline and Modelling Pipeline\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"XAbbAO2r248W\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"We will save 2 pipelines: \\n\",\n",
    "        \"* Both should be used in conjunction to predict Live Data.\\n\",\n",
    "        \"* To predict on Train Set, Test Set we use only pipeline_clf, since the data is already processed.\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"Pipeline responsible for Data Cleaning and Feature Engineering.\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"XCcAlvoG3CRm\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"pipeline_data_cleaning_feat_eng\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"AaHdCf4HKBLg\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"joblib.dump(value=pipeline_data_cleaning_feat_eng ,\\n\",\n",
    "        \"            filename=f\\\"{file_path}/clf_pipeline_data_cleaning_feat_eng.pkl\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"XE-iU6TL3LVI\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"* Pipeline responsible for Feature Scaling, and Model\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"_zEBxfvBqI29\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"pipeline_clf\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"ObL5Iz8tKdsZ\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"joblib.dump(value=pipeline_clf ,\\n\",\n",
    "        \"            filename=f\\\"{file_path}/clf_pipeline_model.pkl\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"yqEUyLG27v9N\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## Feature Importance plot\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"wBiqB55L1Qhk\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"df_feature_importance.plot(kind='bar',x='Feature',y='Importance')\\n\",\n",
    "        \"plt.show()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"NR0taWpn1RuD\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\\n\",\n",
    "        \"plt.savefig(f'{file_path}/features_importance.png', bbox_inches='tight')\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"Good job, you should clear outputs, then run git commands to push files to the repo. Next, move on to Predict Tenure notebook\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"---\"\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"metadata\": {\n",
    "    \"accelerator\": \"GPU\",\n",
    "    \"colab\": {\n",
    "      \"name\": \"Modeling and Evaluation - Predict Customer Churn.ipynb\",\n",
    "      \"provenance\": []\n",
    "    },\n",
    "    \"interpreter\": {\n",
    "      \"hash\": \"8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce\"\n",
    "    },\n",
    "    \"kernelspec\": {\n",
    "      \"display_name\": \"Python 3.8.12 64-bit ('3.8.12': pyenv)\",\n",
    "      \"name\": \"python3\"\n",
    "    },\n",
    "    \"language_info\": {\n",
    "      \"codemirror_mode\": {\n",
    "        \"name\": \"ipython\",\n",
    "        \"version\": 3\n",
    "      },\n",
    "      \"file_extension\": \".py\",\n",
    "      \"mimetype\": \"text/x-python\",\n",
    "      \"name\": \"python\",\n",
    "      \"nbconvert_exporter\": \"python\",\n",
    "      \"pygments_lexer\": \"ipython3\",\n",
    "      \"version\": \"3.8.12 (default, Sep 27 2022, 15:56:02) \\n[GCC 9.4.0]\"\n",
    "    },\n",
    "    \"orig_nbformat\": 2\n",
    "  },\n",
    "  \"nbformat\": 4,\n",
    "  \"nbformat_minor\": 2\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
